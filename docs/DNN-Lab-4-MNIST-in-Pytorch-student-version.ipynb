{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxW4dJFDfX_a"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcTwzhX8fBqs"
      },
      "source": [
        "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "\n",
        "In this exercise, we are using high-level abstractions from torch.nn like nn.Linear.\n",
        "Note: during the next lab session we will go one level deeper and implement more things\n",
        "with bare hands.\n",
        "\n",
        "Tasks:\n",
        "\n",
        " 1. Read the code.\n",
        "\n",
        " 2. Check that the given implementation reaches 95% test accuracy for architecture input-128-128-10 after few epochs.\n",
        "\n",
        " 3. Add the option to use SGD with momentum instead of ADAM.\n",
        "\n",
        " 4. Experiment with different learning rates. Use the provided TrainingVisualizer\n",
        " to plot the learning curves and gradient-to-weight ratios. Compare visualizations\n",
        " for different learning rates for both ADAM and SGD with momentum.\n",
        "\n",
        " 5. Parameterize the constructor by a list of sizes of hidden layers of the MLP.\n",
        " Note that this requires creating a list of layers as an attribute of the Net class,\n",
        " and one can't use a standard Python list containing nn.Modules (why?).\n",
        " Check torch.nn.ModuleList.\n",
        "\n",
        "If you run this notebook locally then you may need to install some packages.\n",
        "It may be achieved by adding the following code cell to the notebook and running it:\n",
        "```\n",
        "!pip install torch torchvision plotly ipywidgets\n",
        "```\n",
        "This notebook can also utilize Colab GPU. However, remember to kill your GPU session after classes as otherwise, you may use all your free GPU time for this week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYAsziKffBFV"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import plotly.graph_objects as go\n",
        "from torch import Tensor\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Allow custom (non-ipywidget) widgets.\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import output\n",
        "\n",
        "    output.enable_custom_widget_manager()\n",
        "\n",
        "# For reproducibility.\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "In ML, *tensor* is just a short name for an n-dimensional array.\n",
        "\n",
        "In other areas like physics, it might mean a multilinear operation that can be represented, after a choice of basis, by an ndarray; this is where we would see all the extra stuff (like covariance/contravariance), like for example on the Wikipedia article for \"tensor\". For us, it's usually just a bunch of numbers.\n",
        "\n",
        "torch.Tensor is can be thought of as a wrapper around numpy ndarray, but:\n",
        "* the interface is slightly different (like `np.expand_dims(x, dim=n-1)` vs `torch.unsqueeze(x, axis=-1)`);\n",
        "* the data can be stored in GPU memory (or others);\n",
        "* it can be part of a computation graph: a computed Tensor has pointers to other Tensors it was computed from, and to functions computing partial derivatives.\n",
        "\n",
        "All the operations defined on for a torch.Tensor (`@`, `.arctan`, `.unsqueeze`, and a hundred others) can also run on a GPU and"
      ],
      "metadata": {
        "id": "p74ud394PINN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_np = np.array([[0, 1, 2], [3, 4, 5]])\n",
        "x = torch.tensor([[0, 1, 2], [3, 4, 5]])  # Also: torch.rand, ones, zeros, rand_like, ...\n",
        "display(x_np, x)"
      ],
      "metadata": {
        "id": "rVRb0_5ePHfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(x_np).equal(x), np.array_equal(x_np, x.numpy())"
      ],
      "metadata": {
        "id": "MqKnrHz2TsLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, x.dtype, x.device, x.requires_grad"
      ],
      "metadata": {
        "id": "WBha_WKbUeFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most operations have an in-place variant with the same name, but with an underscore.\n",
        "This forgets the original value, making the computation of gradients impossible, so most of the time we don't use in-place operations."
      ],
      "metadata": {
        "id": "DJDAbE4ja1BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.add_(2)\n",
        "display(x)"
      ],
      "metadata": {
        "id": "dScxDLG5autQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd\n",
        "Operations on torch tensors remember the computation graph.\n",
        "This allows to compute the gradient of e.g. a loss node over all other nodes with loss.backward()."
      ],
      "metadata": {
        "id": "ZELgpwGhb4QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[0., 1., 2.], [3., 4., 5.]], requires_grad=True)\n",
        "y = torch.sigmoid(x)\n",
        "loss = (((y - 1) ** 2).mean())\n",
        "print(\"x\", x.grad_fn, \", y\", y.grad_fn, \", loss\", loss.grad_fn)\n",
        "print(loss.grad_fn.next_functions)  # type: ignore\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions)  # type: ignore"
      ],
      "metadata": {
        "id": "6cLLEGr_ZzXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method Tensor.backward():\n",
        "* for each node with `requires_grad`: computes the gradients from each .grad_fn and propagates it using the chain rule.\n",
        "* for each leaf node (`requires_grad` with no predecessors that `requires_grad`): accumulates the gradient into the tensor’s `.grad` attribute.\n",
        "\n"
      ],
      "metadata": {
        "id": "mb8K5Qp2fQBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "oTUY8vGAbrfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We say *accumulates* not *stores*, because if .grad already exists, `backward()` adds to it, instead of replacing it."
      ],
      "metadata": {
        "id": "U2TYcjD9guxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss2 = ((x * 0).mean())\n",
        "loss2.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "ZYghiwhqgdMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During (for example) evaluation, you don't need to store the computational graph, so you can disable it:"
      ],
      "metadata": {
        "id": "vGIfu0HuiSfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    y = x * x\n",
        "\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "id": "rtwSgVqriGqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some situations you may need more fine-grained control.\n",
        "You can detach a tensor from the graph, to treat it like a constant tensor."
      ],
      "metadata": {
        "id": "n8HS2G1rihmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x * x\n",
        "print(y.grad_fn, y.requires_grad)\n",
        "y = y.detach()  # Not in-place, returns a new tensor with the same data.\n",
        "print(y.grad_fn, y.requires_grad)"
      ],
      "metadata": {
        "id": "OwK4EhjCidS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules\n",
        "A torch **module** (not *model*) is essentially just an object with a `forward()` method, usually `forward(x: Tensor) -> Tensor`.\n",
        "A network (model) is built as a large module that contains and calls smaller modules, which themselves contain even smaller modules.\n",
        "\n",
        "Basically any callable could be a module, but subclassing `nn.Module` adds features like:\n",
        "* automatically registering and enumerating submodules and trainable parameters,\n",
        "* serializing and storing parameters into files,\n",
        "* adding hooks in the middle of existing models."
      ],
      "metadata": {
        "id": "f4JY4qEyPnMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    This is essentially the same as nn.Linear.\n",
        "\n",
        "    Compare: https://github.com/pytorch/pytorch/blob/v2.9.0/torch/nn/modules/linear.py#L53\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features: int, out_features: int) -> None:\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.weight = nn.Parameter(torch.empty((out_features, in_features)))\n",
        "        self.bias = nn.Parameter(torch.empty(out_features))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self) -> None:\n",
        "        # The initialization used by PyTorch by default, including non-zero biases.\n",
        "        bound = 1 / math.sqrt(self.in_features)\n",
        "        nn.init.uniform_(self.weight, -bound, bound)\n",
        "        nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Input shape: (B*, in_features).\n",
        "        Output shape: (B*, out_features).\n",
        "        \"\"\"\n",
        "        return input @ self.weight.T + self.bias\n"
      ],
      "metadata": {
        "id": "Tm00BKxPLP1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the module behaviour in the **`forward()`** method, not in the special `__call__()`.<br>\n",
        "However, we then use the module directly as a callable, `module()`.<br>\n",
        "This will call `module.forward()`, but can also calls hooks, if any are defined."
      ],
      "metadata": {
        "id": "WGNXaeINl9Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = MyLinear(2, 3)\n",
        "x = torch.rand((7, 5, 2))\n",
        "y = module(x)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "9ysXkw_Tk4Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class **nn.Parameter** just wraps a tensor to indicate that this is a trainable parameter, and changes the default `requires_grad`.<br>\n",
        "When an nn.Parameter is assigned to a field of an nn.Module, it automatically registers it,\n",
        "so that all parameters of this modules and its submodules can be easily accessed."
      ],
      "metadata": {
        "id": "DyrkBRYtnw7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (name, param) in enumerate(module.named_parameters()):\n",
        "    print(f'{i}. \"{name}\":\\t{param}\\n')"
      ],
      "metadata": {
        "id": "TPm6V26snYIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A basic Net"
      ],
      "metadata": {
        "id": "pRoq31JIp3UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Input: shape (B, 28, 28).\n",
        "        Output: class probabilities (after softmax), shape (B, 10).\n",
        "        \"\"\"\n",
        "        x = torch.flatten(x, start_dim=1)  # (B, 728)\n",
        "        x = self.fc1(x)  # (B, 128)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)  # (B, 128)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)  # (B, 10)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "VBmQFoLSIf3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning to a nn.Module to a field of nn.Module automatically registers it as a submodule.<br>\n",
        "You can iterate over all submodules (recursively) with `.named_modules()` or over direct children only with `.named_children()`."
      ],
      "metadata": {
        "id": "icH4jOY0JYh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "for i, (name, submodule) in enumerate(net.named_modules()):\n",
        "    print(f'{i}. \"{name}\":\\t{submodule}')"
      ],
      "metadata": {
        "id": "graoNYBrI2Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `.train()` and `.eval()` methods set the `training` flag of a module and all its submodules.<br>\n",
        "This changes the behaviour of certain modules like BatchNorm and Dropout (see next labs).\n",
        "\n",
        "Forgetting to switch the training mode is a common bug that can cause weird behaviour."
      ],
      "metadata": {
        "id": "Z_DWIcjGI-Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.train()\n",
        "print(net.fc1.training)\n",
        "net.eval()\n",
        "print(net.fc1.training)"
      ],
      "metadata": {
        "id": "7OwnqI4yIlVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that operations on a module (`.train()`, `.eval()`, `.to(dtype)`, `.to(device)`) modify it in-place.<br>\n",
        "Operations on a tensor without a trailing underscore (including `.to(dtype)`, `.to(device)`) return a new tensor and leave the original unchanged\n"
      ],
      "metadata": {
        "id": "R-yAMiOm0NRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test code"
      ],
      "metadata": {
        "id": "-4k5AmCFvjpi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "ThUOOE4c8lAz"
      },
      "outputs": [],
      "source": [
        "# @title <small>Helper class: TrainingVisualizer</small>\n",
        "\n",
        "class TrainingVisualizer:\n",
        "    def __init__(self, log_interval: int = 10):\n",
        "        self.log_interval = log_interval\n",
        "        self.train_loss_fig = self.init_line_plot(\n",
        "            title=\"Training loss\", xaxis_title=\"Step\"\n",
        "        )\n",
        "        self.grad_to_weight_fig = self.init_line_plot(\n",
        "            title=\"Gradient standard deviation to weight standard deviation ratio at 1st layer\",\n",
        "            xaxis_title=\"Step\",\n",
        "            yaxis_title=\"Gradient to weight ratio (log scale)\",\n",
        "            yaxis_type=\"log\",\n",
        "        )\n",
        "        self.test_acc_fig = self.init_line_plot(\n",
        "            title=\"Test accuracy\", x=[], xaxis_title=\"Epoch\", mode=\"lines+markers\"\n",
        "        )\n",
        "\n",
        "        # Parameters related to current tracked model and its training\n",
        "        self.first_linear_layer = None\n",
        "        self.lr = None\n",
        "        self.trace_idx = -1\n",
        "\n",
        "    def init_line_plot(\n",
        "        self,\n",
        "        title: str,\n",
        "        x=None,\n",
        "        xaxis_title: str | None = None,\n",
        "        yaxis_title: str | None = None,\n",
        "        yaxis_type: str = \"linear\",\n",
        "        mode: str = \"lines\",\n",
        "    ) -> go.FigureWidget:\n",
        "        fig = go.Figure()\n",
        "        fig.update_layout(\n",
        "            title=title,\n",
        "            title_x=0.5,\n",
        "            xaxis_title=xaxis_title,\n",
        "            yaxis_title=yaxis_title,\n",
        "            height=400,\n",
        "            width=1500,\n",
        "            margin=dict(b=10, t=60),\n",
        "        )\n",
        "        fig.update_yaxes(type=yaxis_type)\n",
        "        # We cannot add new traces dynamically because Colab has a problem with widgets\n",
        "        # from plotly (traces added dynamically are rendered twice).\n",
        "        # As an ugly workaround we create a lot of empty traces and update them later\n",
        "        # with actual data. Empty traces are not plotted.\n",
        "        for _ in range(25):\n",
        "            fig.add_trace(go.Scatter(x=x, y=[], showlegend=True, mode=mode))\n",
        "\n",
        "        fig_widget = go.FigureWidget(fig)\n",
        "        display(fig_widget)\n",
        "        return fig_widget\n",
        "\n",
        "    def track_model(\n",
        "        self, model: torch.nn.Module, optimizer: torch.optim.Optimizer, lr: float\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Start tracking training metrics for a new model.\n",
        "        \"\"\"\n",
        "\n",
        "        for field in model.__dict__[\"_modules\"].values():\n",
        "            if isinstance(field, nn.Linear):\n",
        "                self.first_linear_layer = field\n",
        "                break\n",
        "            elif isinstance(field, nn.ModuleList):\n",
        "                self.first_linear_layer = field[0]\n",
        "                break\n",
        "\n",
        "        self.lr = lr\n",
        "        self.trace_idx += 1\n",
        "\n",
        "        optim_name = type(optimizer).__name__\n",
        "        self.train_loss_fig.data[self.trace_idx].name = f\"{optim_name}, {lr}\"\n",
        "        self.grad_to_weight_fig.data[self.trace_idx].name = f\"{optim_name}, {lr}\"\n",
        "        self.test_acc_fig.data[self.trace_idx].name = f\"{optim_name}, {lr}\"\n",
        "\n",
        "    def plot_gradients_and_loss(self, batch_idx: int, loss: float) -> None:\n",
        "        if batch_idx % self.log_interval == 0:\n",
        "            self.train_loss_fig.data[self.trace_idx].y += (loss,)\n",
        "\n",
        "            layer = self.first_linear_layer\n",
        "            grad_to_weight_ratio = (\n",
        "                self.lr * layer.weight.grad.std() / layer.weight.std()\n",
        "            ).item()\n",
        "\n",
        "            self.grad_to_weight_fig.data[self.trace_idx].y += (grad_to_weight_ratio,)\n",
        "\n",
        "    def plot_accuracy(self, epoch: int, accuracy: float) -> None:\n",
        "        self.test_acc_fig.data[self.trace_idx].x += (epoch,)\n",
        "        self.test_acc_fig.data[self.trace_idx].y += (accuracy,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMtap4QCfBH8"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "    model: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "    train_loader: torch.utils.data.DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epoch: int,\n",
        "    log_interval: int,\n",
        "    visualizer: TrainingVisualizer,\n",
        "    verbose: bool = False,\n",
        ") -> None:\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move data to the device (e.g. GPU #0) where model parameters are.\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Since `backward()` will accumuate gradients, remember to reset them.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass.\n",
        "        output = model(data)  # Logs of class probabilites, shape (B, 10)\n",
        "        loss = F.nll_loss(output, target)  # Shape (1,)\n",
        "\n",
        "        # Backward pass.\n",
        "        loss.backward()\n",
        "\n",
        "        visualizer.plot_gradients_and_loss(batch_idx, loss.item())\n",
        "\n",
        "        # For each parameter, updates the tensor's value using its .grad.\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            if verbose:\n",
        "                done, total = batch_idx * len(data), len(train_loader.dataset)\n",
        "                print(\n",
        "                    f\"Train Epoch: {epoch} [{done}/{total} images ({done / total:.0%})]\\t\"\n",
        "                    + f\"Loss: {loss.item():.6f}\"\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(\n",
        "    model: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "    test_loader: torch.utils.data.DataLoader,\n",
        "    epoch: int,\n",
        "    visualizer: TrainingVisualizer,\n",
        "    verbose: bool = False,\n",
        ") -> None:\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            # Accumulate sum of dataitem losses and only divide by n_total at the end.\n",
        "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            n_correct += (pred == target).sum().item()\n",
        "            n_total += len(target)\n",
        "\n",
        "    test_loss /= n_total\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nTest loss: {test_loss:.4f}, Accuracy: {n_correct}/{n_total} ({n_correct/n_total:.0%})\\n\")\n",
        "    visualizer.plot_accuracy(epoch, 100.0 * n_correct / n_total)"
      ],
      "metadata": {
        "id": "ablF0fPdwxrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "NNiik6WM0-yy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5GlMs1-fBKP"
      },
      "outputs": [],
      "source": [
        "# Training uses more memory than test (due to gradient computations),\n",
        "# so we can set test_batch_size to be larger.\n",
        "epochs = 5\n",
        "batch_size = 256\n",
        "test_batch_size = 1000\n",
        "lr = 1e-2\n",
        "log_interval = 10\n",
        "\n",
        "# Use CUDA if a CUDA GPU is available, otherwise we'll run on CPU.\n",
        "# You could also use \"mps\" for Apple Silicon, and some others,\n",
        "# though support for less common operations may vary.\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and dataloader\n",
        "Any sequence of dataitems (and even some iterables) can be used as a ***dataset***.<br>\n",
        "A dataitem can be for example an (input image, output label) pair.<br>\n",
        "Torch datasets usually allow passing a transformation: it is then applied whenever you retrieve an item with `dataset[i]`.\n",
        "\n",
        "A ***dataloader*** manages parallel loading (it can create worker threads that call `dataset[i]` in parallel), batching, shuffling, sometimes moving data between devices."
      ],
      "metadata": {
        "id": "oPwbKOMd1Nt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0KPoUtsfBOs"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n",
        ")\n",
        "train_dataset = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, **kwargs)"
      ],
      "metadata": {
        "id": "QAX0_P-A1Uif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running it all"
      ],
      "metadata": {
        "id": "WQL6gbIt3MY2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezvIQbgsfBRT"
      },
      "outputs": [],
      "source": [
        "model = Net().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "visualizer = TrainingVisualizer(log_interval=log_interval)\n",
        "visualizer.track_model(model, optimizer, lr)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(\n",
        "        model,\n",
        "        device,\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        epoch,\n",
        "        log_interval,\n",
        "        visualizer,\n",
        "        verbose=True,\n",
        "    )\n",
        "    test(model, device, test_loader, epoch, visualizer, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}